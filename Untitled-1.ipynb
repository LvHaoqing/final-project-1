{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\src\\wls_filter.py:61: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  OUT = spsolve(A, IN.flatten(order='F'))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "HDR_Filter = FakeHDR(True)\n",
    "image = cv2.imread(r'C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949-x4.png')\n",
    "if image is not None:\n",
    "    output_image = HDR_Filter.process(image)\n",
    "    if output_image is not None:\n",
    "        cv2.imwrite('result.jpg', 255 * output_image)\n",
    "    else:\n",
    "        print(\"Failed to process image.\")\n",
    "else:\n",
    "    print(\"Failed to load image.\")\n",
    "Show_origin_and_output(image, output_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.wls_filter import wlsFilter\n",
    "from src.srs import SRS\n",
    "from src.virtual_ev import VIG \n",
    "from src.tonemap import *\n",
    "def Show_origin_and_output(origin, I):\n",
    "   plt.figure(figsize=(12, 6))\n",
    "   plt.subplots_adjust(left=0,right=1,bottom=0,top=1, wspace=0.005, hspace=0)\n",
    "   plt.subplot(121),plt.imshow(np.flip(origin, 2)),plt.title('Origin')\n",
    "   plt.axis('off')\n",
    "   plt.subplot(122),plt.imshow(np.flip(I, 2)),plt.title('Fake HDR')\n",
    "   plt.axis('off')\n",
    "   plt.savefig('compare.png', bbox_inches='tight', pad_inches=0)\n",
    "   plt.show()\n",
    "class FakeHDR():  \n",
    "    def __init__(self, flag):\n",
    "        self.weighted_fusion = flag\n",
    "        self.wls = wlsFilter\n",
    "        self.srs = SRS\n",
    "        self.vig = VIG\n",
    "        self.tonemap = tonereproduct\n",
    "    def process(self, image):    \n",
    "        if image.shape[2] == 4:\n",
    "            image = image[:,:,0:3]\n",
    "        S = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)/255.0\n",
    "        image = 1.0*image/255\n",
    "        L = 1.0*S\n",
    "        I = self.wls(S)\n",
    "        R = np.log(L+1e-22) - np.log(I+1e-22)\n",
    "        R_ = self.srs(R, L)\n",
    "        I_K = self.vig(L, 1.0 - L)\n",
    "        result_ = self.tonemap(image, L, R_, I_K, self.weighted_fusion)\n",
    "        return result_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selective Reflectance Scaling\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "\n",
    "def SRS(reflectance, illuminace):\n",
    "    \n",
    "    r_R = 0.5\n",
    "    def compare_func(r, i, m):    \n",
    "        return r * (i/m)**r_R if i > m else r \n",
    "\n",
    "    srs_fun = np.vectorize(compare_func)\n",
    "    mean_I = np.mean(illuminace)\n",
    "    result = srs_fun(reflectance, illuminace, mean_I)\n",
    "    return result\n",
    "\n",
    "# Unit test\n",
    "if __name__ == '__main__':\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tone Reproduction\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def tonereproduct(bgr_image, L, R_, Ik_list, FLAG):\n",
    "   \n",
    "    Lk_list = [ np.exp(R_) * Ik for Ik in Ik_list ] \n",
    "    L = L + 1e-22 \n",
    "\n",
    "    rt = 1.0\n",
    "    b, g, r = cv2.split(bgr_image)\n",
    "    if FLAG == False:\n",
    "        Sk_list = [cv2.merge((Lk*(b/L)**rt, Lk*(g/L)**rt, Lk*(r/L)**rt)) for Lk in Lk_list]\n",
    "        return Sk_list[2]\n",
    "    else:  \n",
    "        Wk_list = []\n",
    "        for index, Ik in enumerate(Ik_list):\n",
    "            if index < 3:\n",
    "                wk = Ik / np.max(Ik)\n",
    "            else:\n",
    "                temp = 0.5*(1 - Ik)\n",
    "                wk = temp / np.max(temp)\n",
    "            Wk_list.append(wk)\n",
    "\n",
    "        A = np.zeros_like(Wk_list[0])\n",
    "        B = np.zeros_like(Wk_list[0])\n",
    "        for lk, wk in zip(Lk_list, Wk_list):\n",
    "            A = A + lk * wk \n",
    "            B = B + wk\n",
    "\n",
    "        L_ = (A/B)\n",
    "        ratio = np.clip(L_/L, 0, 3) \n",
    "        b_ = ratio * b\n",
    "        g_ = ratio * g\n",
    "        r_ = ratio * r\n",
    "        out = cv2.merge( ( b_, g_, r_ ) )\n",
    "        return np.clip(out, 0.0, 1.0)\n",
    "\n",
    "# Unit test\n",
    "if __name__ == '__main__':\n",
    "    pass \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtual Illumination Generation (VIG)\n",
    "import cv2\n",
    "import numpy as np\n",
    "def scale_fun(v_, mean_i_, max_i_):\n",
    "\n",
    "    r = 1.0 - mean_i_/max_i_    \n",
    "    fv = lambda v : r*( 1/(1+np.exp(-1.0*(v - mean_i_))) - 0.5 )\n",
    "    \n",
    "    fv_k_ = [fv(vk) for vk in v_]\n",
    "    return fv_k_\n",
    "\n",
    "def VIG(illuminace, inv_illuminace):\n",
    "    inv_illuminace /=np.max(inv_illuminace)\n",
    "    mi = np.mean(illuminace)\n",
    "\n",
    "    maxi = np.max(illuminace)\n",
    "    v1 = 0.2;    v3 = mi;    v2 = 0.5 * (v1 + v3)\n",
    "    v5 = 0.8;    v4 = 0.5 * (v3 + v5)\n",
    "    v = [v1, v2, v3, v4, v5]\n",
    "    fvk_list = scale_fun(v, mi, maxi)\n",
    "    I_k = [(1 + fvk) * (illuminace + fvk * inv_illuminace) for fvk in fvk_list]  \n",
    "\n",
    "    return I_k\n",
    "\n",
    "\n",
    "# Unit test\n",
    "if __name__ == '__main__':\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31493\\AppData\\Local\\Temp\\ipykernel_22344\\768301506.py:27: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  OUT = spsolve(A, IN.flatten(order='F'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     37\u001b[0m image1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39mimage \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(image)\n\u001b[1;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mwlsFilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n\u001b[0;32m     40\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36mwlsFilter\u001b[1;34m(IN, Lambda, Alpha)\u001b[0m\n\u001b[0;32m     25\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m (e \u001b[38;5;241m+\u001b[39m w \u001b[38;5;241m+\u001b[39m s \u001b[38;5;241m+\u001b[39m n)\n\u001b[0;32m     26\u001b[0m A \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m+\u001b[39m A\u001b[38;5;241m.\u001b[39mtranspose() \u001b[38;5;241m+\u001b[39m spdiags(D, \u001b[38;5;241m0\u001b[39m, k, k)\n\u001b[1;32m---> 27\u001b[0m OUT \u001b[38;5;241m=\u001b[39m \u001b[43mspsolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mreshape(OUT, (height, width), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\31493\\anaconda3\\envs\\mindspore\\lib\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:293\u001b[0m, in \u001b[0;36mspsolve\u001b[1;34m(A, b, permc_spec, use_umfpack)\u001b[0m\n\u001b[0;32m    291\u001b[0m indptr \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mintc, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    292\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ColPerm\u001b[38;5;241m=\u001b[39mpermc_spec)\n\u001b[1;32m--> 293\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43m_superlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgssv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    296\u001b[0m     warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix is exactly singular\u001b[39m\u001b[38;5;124m\"\u001b[39m, MatrixRankWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.sparse.linalg import spsolve, lsqr\n",
    "def wlsFilter(IN, Lambda=1.0, Alpha=1.2):\n",
    "    L = np.log(IN+1e-22)      \n",
    "    smallNum = 1e-6\n",
    "    height, width = IN.shape\n",
    "    k = height * width\n",
    "    dy = np.diff(L, n=1, axis=0)   \n",
    "    dy = -Lambda/(np.abs(dy)**Alpha + smallNum)\n",
    "    dy = np.pad(dy, ((0,1),(0,0)), 'constant')    \n",
    "    dy = dy.flatten(order='F')\n",
    "    dx = np.diff(L, n=1, axis=1)\n",
    "    dx = -Lambda/(np.abs(dx)**Alpha + smallNum)\n",
    "    dx = np.pad(dx, ((0,0),(0,1)), 'constant')    \n",
    "    dx = dx.flatten(order='F') \n",
    "    B = np.concatenate([[dx], [dy]], axis=0)\n",
    "    d = np.array([-height,  -1])\n",
    "    A = spdiags(B, d, k, k) \n",
    "    e = dx \n",
    "    w = np.pad(dx, (height, 0), 'constant'); w = w[0:-height]\n",
    "    s = dy\n",
    "    n = np.pad(dy, (1, 0), 'constant'); n = n[0:-1]\n",
    "    D = 1.0 - (e + w + s + n)\n",
    "    A = A + A.transpose() + spdiags(D, 0, k, k)\n",
    "    OUT = spsolve(A, IN.flatten(order='F'))\n",
    "    return np.reshape(OUT, (height, width), order='F') \n",
    "\n",
    "\n",
    "# Unit test\n",
    "if __name__ == '__main__':\n",
    "    image = cv2.imread('1949-x4.png')\n",
    "    if image.shape[2] == 4:        # Format RGBA\n",
    "        image = image[:,:, 0:3]    # Discard alpha channel \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image1 = 1.0*image / np.max(image)\n",
    "    result = wlsFilter(image1)\n",
    "    cv2.imshow('1', result)\n",
    "    cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、PSNR\n",
    "1.1 原理\n",
    "PSNR 是一种衡量图像质量的指标，它是通过比较原始图像和失真图像之间的差异来计算的。具体来说，PSNR 是通过比较两幅图像的每个像素值来计算的。\n",
    "PSNR 主要比较的是两幅图像的每个像素值的差异，这种差异被称为 “噪声”。如果两幅图像完全相同，那么噪声就为零，PSNR 就为无穷大。如果两幅图像有很大的差异，那么噪声就会很大，PSNR 就会相应地减小。因此，PSNR 越大，表示图像质量越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:78\u001b[1;36m\u001b[0m\n\u001b[1;33m    img2 = cv2.imread(\"C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949-x4.png\")  # 读入图片2\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def reorder_image(img, input_order='HWC', output_order='HWC'):\n",
    "    ''' reorder_image '''\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' \"'HWC' and 'CHW'\")\n",
    "    if output_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong output_order {output_order}. Supported output_orders are ' \"'HWC' and 'CHW'\")\n",
    "    if len(img.shape) == 2:\n",
    "        img, input_order = img[..., None], 'CHW'\n",
    "    if input_order == 'CHW' and output_order == 'HWC':\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    elif input_order == 'HWC' and output_order == 'CHW':\n",
    "        img = img.transpose(2, 0, 1)\n",
    "    return img\n",
    "\n",
    "def _convert_input_type_range(img):\n",
    "    ''' convert input to [0, 1] '''\n",
    "    img_type = img.dtype\n",
    "    img = img.astype(np.float32)\n",
    "    if img_type == np.float32:\n",
    "        pass\n",
    "    elif img_type == np.uint8:\n",
    "        img /= 255.\n",
    "    else:\n",
    "        raise TypeError(f'The img type should be np.float32 or np.uint8, but got {img_type}')\n",
    "    return img\n",
    "    \n",
    "def _convert_output_type_range(img, dst_type):\n",
    "    ''' convert output to dst_type '''\n",
    "    if dst_type not in (np.uint8, np.float32):\n",
    "        raise TypeError(f'The dst_type should be np.float32 or np.uint8, but got {dst_type}')\n",
    "    if dst_type == np.uint8:\n",
    "        img = img.round()\n",
    "    else:\n",
    "        img /= 255.\n",
    "    return img.astype(dst_type)\n",
    "\n",
    "def bgr2ycbcr(img, y_only=False):\n",
    "    ''' bgr space to ycbcr space '''\n",
    "    img_type = img.dtype\n",
    "    img = _convert_input_type_range(img)\n",
    "    if y_only:\n",
    "        out_img = np.dot(img, [24.966, 128.553, 65.481]) + 16.0\n",
    "    else:\n",
    "        out_img = np.matmul(\n",
    "            img, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786], [65.481, -37.797, 112.0]]) + [16, 128, 128]\n",
    "    out_img = _convert_output_type_range(out_img, img_type)\n",
    "    return out_img\n",
    "\n",
    "def calculate_psnr(img, img2, crop_border, input_order='HWC', test_y_channel=False, **_kwargs):\n",
    "    ''' calculate_psnr '''\n",
    "    assert img.shape == img2.shape, (f'Image shapes are different: {img.shape}, {img2.shape}.')\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' '\"HWC\" and \"CHW\"')\n",
    "    if not isinstance(crop_border, (list, tuple)):\n",
    "        crop_border = (crop_border, crop_border)\n",
    "    img = reorder_image(img, input_order=input_order).astype(np.float64)\n",
    "    img2 = reorder_image(img2, input_order=input_order).astype(np.float64)\n",
    "    if crop_border[0] != 0:\n",
    "        img = img[crop_border[0]:-crop_border[0], ...]\n",
    "        img2 = img2[crop_border[0]:-crop_border[0], ...]\n",
    "    if crop_border[1] != 0:\n",
    "        img = img[:, crop_border[1]:-crop_border[1], ...]\n",
    "        img2 = img2[:, crop_border[1]:-crop_border[1], ...]\n",
    "    if test_y_channel:\n",
    "        img = bgr2ycbcr(img.astype(np.float32) / 255., y_only=True) * 255\n",
    "        img2 = bgr2ycbcr(img2.astype(np.float32) / 255., y_only=True) * 255\n",
    "    mse = np.mean((img - img2)**2)                 # MSE均方误差\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    PSNR_result = 20. * np.log10(255. / np.sqrt(mse))\n",
    "    return PSNR_result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timg1 = cv2.imread(\"C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949.png\")  # 读入图片1\n",
    "    img2 = cv2.imread(\"C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949-x4.png\")  # 读入图片2\n",
    "    PSNR_result = calculate_psnr(img1, img2, 4)\n",
    "\n",
    "    print(\"PSNR_result = \",PSNR_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、SSIM\n",
    "2.1 原理\n",
    "SSIM（结构相似性）是一种衡量两幅图像相似度的指标。SSIM 主要比较的是两幅图像的亮度、对比度和结构。这三个因素都是人类视觉系统在评价图像质量时的重要因素。因此，SSIM 能够更好地反映人类视觉系统对图像质量的感知。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2400755482.py, line 97)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 97\u001b[1;36m\u001b[0m\n\u001b[1;33m    img1 = cv2.imread(\"C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949.png\")  # 读入图片1\u001b[0m\n\u001b[1;37m                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def reorder_image(img, input_order='HWC', output_order='HWC'):\n",
    "    ''' reorder_image '''\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' \"'HWC' and 'CHW'\")\n",
    "    if output_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong output_order {output_order}. Supported output_orders are ' \"'HWC' and 'CHW'\")\n",
    "    if len(img.shape) == 2:\n",
    "        img, input_order = img[..., None], 'CHW'\n",
    "    if input_order == 'CHW' and output_order == 'HWC':\n",
    "        img = img.transpose(1, 2, 0)\n",
    "    elif input_order == 'HWC' and output_order == 'CHW':\n",
    "        img = img.transpose(2, 0, 1)\n",
    "    return img\n",
    "\n",
    "def _convert_input_type_range(img):\n",
    "    ''' convert input to [0, 1] '''\n",
    "    img_type = img.dtype\n",
    "    img = img.astype(np.float32)\n",
    "    if img_type == np.float32:\n",
    "        pass\n",
    "    elif img_type == np.uint8:\n",
    "        img /= 255.\n",
    "    else:\n",
    "        raise TypeError(f'The img type should be np.float32 or np.uint8, but got {img_type}')\n",
    "    return img\n",
    "\n",
    "def _convert_output_type_range(img, dst_type):\n",
    "    ''' convert output to dst_type '''\n",
    "    if dst_type not in (np.uint8, np.float32):\n",
    "        raise TypeError(f'The dst_type should be np.float32 or np.uint8, but got {dst_type}')\n",
    "    if dst_type == np.uint8:\n",
    "        img = img.round()\n",
    "    else:\n",
    "        img /= 255.\n",
    "    return img.astype(dst_type)\n",
    "\n",
    "def bgr2ycbcr(img, y_only=False):\n",
    "    ''' bgr space to ycbcr space '''\n",
    "    img_type = img.dtype\n",
    "    img = _convert_input_type_range(img)\n",
    "    if y_only:\n",
    "        out_img = np.dot(img, [24.966, 128.553, 65.481]) + 16.0\n",
    "    else:\n",
    "        out_img = np.matmul(\n",
    "            img, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786], [65.481, -37.797, 112.0]]) + [16, 128, 128]\n",
    "    out_img = _convert_output_type_range(out_img, img_type)\n",
    "    return out_img\n",
    "\n",
    "def _ssim(img, img2):\n",
    "    ''' ssim '''\n",
    "    c1, c2 = (0.01 * 255)**2, (0.03 * 255)**2\n",
    "    img = img.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "    mu1 = cv2.filter2D(img, -1, window)[5:-5, 5:-5]\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq, mu2_sq = mu1**2, mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def calculate_ssim(img, img2, crop_border, input_order='HWC', test_y_channel=False, **_kwargs):\n",
    "    ''' calculate_ssim '''\n",
    "    assert img.shape == img2.shape, (f'Image shapes are different: {img.shape}, {img2.shape}.')\n",
    "    if input_order not in ['HWC', 'CHW']:\n",
    "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' '\"HWC\" and \"CHW\"')\n",
    "    if not isinstance(crop_border, (list, tuple)):\n",
    "        crop_border = (crop_border, crop_border)\n",
    "    img = reorder_image(img, input_order=input_order)\n",
    "    img2 = reorder_image(img2, input_order=input_order)\n",
    "    img = img.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    if crop_border[0] != 0:\n",
    "        img = img[crop_border[0]:-crop_border[0], ...]\n",
    "        img2 = img2[crop_border[0]:-crop_border[0], ...]\n",
    "    if crop_border[1] != 0:\n",
    "        img = img[:, crop_border[1]:-crop_border[1], ...]\n",
    "        img2 = img2[:, crop_border[1]:-crop_border[1], ...]\n",
    "    if test_y_channel:\n",
    "        img = bgr2ycbcr(img.astype(np.float32) / 255., y_only=True)[..., None] * 255\n",
    "        img2 = bgr2ycbcr(img2.astype(np.float32) / 255., y_only=True)[..., None] * 255\n",
    "    ssims = []\n",
    "    for i in range(img.shape[2]):\n",
    "        ssims.append(_ssim(img[..., i], img2[..., i]))\n",
    "    ssims_result = np.array(ssims).mean()\n",
    "    return ssims_result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img1 = cv2.imread(\"C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949.png\")  # 读入图片1\n",
    "    img2 = cv2.imread(\"C:\\Users\\31493\\Desktop\\singleLDR2HDR-master\\1949-x4.png\")  # 读入图片2\n",
    "    ssims_result = calculate_ssim(img1, img2, 4)\n",
    "\n",
    "    print(\"SSIM_result = \", ssims_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
